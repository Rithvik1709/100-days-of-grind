# ğŸ“Š Machine Learning Model Evaluation

This project demonstrates the evaluation of a supervised machine learning model using the **Breast Cancer Dataset**. The model is assessed using key metrics such as **Accuracy, Precision, Recall, F1-Score, and AUC-ROC Curve**.

---

## ğŸ“‚ Project Structure

```
ML_Evaluation_Project/
â”‚â”€â”€ breast_cancer_data.csv  # Dataset
â”‚â”€â”€ evaluate_model.py  # Code for model evaluation
â”‚â”€â”€ ML_Evaluation.ipynb  # Jupyter Notebook with explanations
â”‚â”€â”€ README.md  # Project documentation
```

---

## ğŸ“Œ Dataset

The dataset used is the **Breast Cancer Dataset** from Scikit-Learn. It contains multiple features related to cell characteristics and a **target** column indicating whether the tumor is malignant (1) or benign (0).



---

## ğŸš€ How to Run

### 1ï¸âƒ£ **Set Up the Environment**
Install the required dependencies:

```bash
pip install numpy pandas scikit-learn matplotlib
```

### 2ï¸âƒ£ **Run the Evaluation Script**
Navigate to the `src/` folder and run:

```bash
python evaluate_model.py
```

This will output evaluation metrics and display the **ROC Curve**.

### 3ï¸âƒ£ **Explore the Jupyter Notebook**
To interactively explore the dataset and metrics, open the notebook:

```bash
jupyter notebook notebooks/ML_Evaluation.ipynb
```

---

## ğŸ“Š Evaluation Metrics
The model is evaluated based on:

- **Accuracy**: Measures overall correctness.
- **Precision**: How many predicted positive cases were actually positive.
- **Recall (Sensitivity)**: How many actual positive cases were correctly predicted.
- **F1-Score**: Harmonic mean of Precision & Recall.
- **AUC-ROC Curve**: Measures the classifier's ability to distinguish between classes.

---

## ğŸ“ˆ Results
Upon execution, the script will display the following metrics:

```bash
Accuracy: 0.96
Precision: 0.98
Recall: 0.94
F1-Score: 0.96
```